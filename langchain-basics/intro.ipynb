{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e405d6b3",
   "metadata": {},
   "source": [
    "## Testing out the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac4fd8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ae9354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()  # Load environment variables from a .env file if present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25e122c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.27'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca2cb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_flash_model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abaff17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(\n",
    "    model=\"openai/gpt-oss-20b\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    reasoning_format=\"parsed\",\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "638d62ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is **New\\u202fDelhi**.'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what is the capital of india\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f6db1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is **New Delhi**.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_flash_model.invoke(\"what is the capital of india\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9039a1",
   "metadata": {},
   "source": [
    "### Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39946a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03572908416390419,\n",
       " 0.014558478258550167,\n",
       " 0.011592254973948002,\n",
       " -0.08969993889331818,\n",
       " -0.009068180806934834,\n",
       " 0.013664662837982178,\n",
       " 0.011340967379510403,\n",
       " -0.005701108369976282,\n",
       " -0.027033332735300064,\n",
       " 3.775993536692113e-05]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\")\n",
    "embeddings = embedding_model.embed_query(text=\"What's our Q1 revenue?\", output_dimensionality=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "442f4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c83f8c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={\"device\": \"cpu\"},\n",
    ")\n",
    "embeddings = embedding_model.embed_query(text=\"What's our Q1 revenue?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "469390e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ac8699",
   "metadata": {},
   "source": [
    "## Langchain Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f770da5",
   "metadata": {},
   "source": [
    "### Basic Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08a51825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate, load_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c604238",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are a helpful assistant that can generate a short report on the topic: {paper_input}\n",
    "    The report should be in the style of {style_input} and the length should be {length_input}\n",
    "    \"\"\",\n",
    "    input_variables=[\"paper_input\", \"style_input\", \"length_input\"]\n",
    ")\n",
    "\n",
    "template.save(\"./prompt_templates/template.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3dfce506",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = load_prompt(\"./prompt_templates/template.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "34432a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template.format(\n",
    "        paper_input=\"Attention is all you need\", style_input=\"Beginner-Friendly\", length_input=\"Short (1-2 paragraphs)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1cea0e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    You are a helpful assistant that can generate a short report on the topic: Attention is all you need\n",
      "    The report should be in the style of Beginner-Friendly and the length should be Short (1-2 paragraphs)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print (prompt)\n",
    "\n",
    "### Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7c294e",
   "metadata": {},
   "source": [
    "### Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d88b3774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1ac7f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is **Paris**.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant that can answer questions and help with tasks.\"),\n",
    "    HumanMessage(content=\"What is the capital of France?\"),\n",
    "]\n",
    "\n",
    "result = model.invoke(messages)\n",
    "\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d2d852",
   "metadata": {},
   "source": [
    "### Dynammic list of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1dcdaaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate(messages=[\n",
    "    SystemMessage(content=\"You are a helpful assistant who is an expert in the domain: {domain}\"),\n",
    "    HumanMessage(content=\"Explain the topic in simple terms: {topic}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37fc3c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful assistant who is an expert in the domain: {domain}', additional_kwargs={}, response_metadata={}), HumanMessage(content='Explain the topic in simple terms: {topic}', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "prompt = chat_template.invoke({\"domain\": \"AI\", \"topic\": \"Self Attention\"})\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b60a1e",
   "metadata": {},
   "source": [
    "### The above does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "03bbd30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful assistant who is an expert in the domain: AI', additional_kwargs={}, response_metadata={}), HumanMessage(content='Explain the topic in simple terms in 3-5 sentences: Self Attention', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "chat_template = ChatPromptTemplate(messages=[\n",
    "    (\"system\", \"You are a helpful assistant who is an expert in the domain: {domain}\"),\n",
    "    (\"human\", \"Explain the topic in simple terms in 3-5 sentences: {topic}\"),\n",
    "])\n",
    "prompt = chat_template.invoke({\"domain\": \"AI\", \"topic\": \"Self Attention\"})\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "69b273c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self‑attention is a way for a model to look at all the words in a sentence at once and decide how much each word should influence every other word.  \n",
      "For each word, the model creates three vectors—query, key, and value—then compares the query of one word with the keys of all words to get a “similarity score.”  \n",
      "These scores are turned into weights (via a softmax) that say how much attention each word should give to the others, and the weighted sum of the value vectors gives the new representation for that word.  \n",
      "Because every word can attend to every other word, the model captures long‑range relationships and context without needing to process the sentence sequentially.  \n",
      "This mechanism is the core of transformer models, enabling them to understand and generate language efficiently.\n"
     ]
    }
   ],
   "source": [
    "result = model.invoke(prompt)\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531a16a3",
   "metadata": {},
   "source": [
    "### Message Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fe629272",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_messages = [\n",
    "    HumanMessage(content=\"I want to request a refund for my order #12345.\"),\n",
    "    AIMessage(content=\"Your refund request for order #12345 has been initiated. It will be processed in 3-5 business days.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "59e7906d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to request a refund for my order #12345.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_messages[0].content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "55493bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant that can answer questions and help with tasks.', additional_kwargs={}, response_metadata={}), HumanMessage(content='I want to request a refund for my order #12345.', additional_kwargs={}, response_metadata={}), AIMessage(content='Your refund request for order #12345 has been initiated. It will be processed in 3-5 business days.', additional_kwargs={}, response_metadata={}), HumanMessage(content='how many day again?', additional_kwargs={}, response_metadata={})])\n"
     ]
    }
   ],
   "source": [
    "chat_template = ChatPromptTemplate(messages=[\n",
    "    (\"system\", \"You are a helpful assistant that can answer questions and help with tasks.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{query}\"),\n",
    "])\n",
    "\n",
    "prompt = chat_template.invoke({\"query\": \"how many day again?\", \"chat_history\": history_messages})\n",
    "\n",
    "pprint(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "186112e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It will take **3–5 business days** to complete the refund.  \n",
      "That means the processing time is counted only on weekdays (Monday‑Friday), excluding public holidays. If you have any more questions, just let me know!\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3977873",
   "metadata": {},
   "source": [
    "## Structured Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "075c1c27",
   "metadata": {},
   "source": [
    "### Typed Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bbf059d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import TypedDict, Annotated, Optional, Literal, List\n",
    "\n",
    "class Person(TypedDict):\n",
    "    name: str\n",
    "    age: int\n",
    "    email: str\n",
    "\n",
    "person = Person(name=\"John\", age=30, email=\"john@example.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c1cb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "person = Person(name=123, age=30, email=\"john@example.com\") # this is wrong according to the type def, but it will not raise an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "bdaa1dba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentiment': 'positive',\n",
      " 'summary': 'The phone offers great camera performance, long battery life, and '\n",
      "            'a reasonable price, with a decent display and solid gaming '\n",
      "            'experience, though it heats up after extended play. Overall, a '\n",
      "            'solid value.'}\n"
     ]
    }
   ],
   "source": [
    "# create a dummy review for a mobile phone in plain text\n",
    "review = \"\"\"\n",
    "This is a decent phone! I love the camera and the battery life is amazing. Also, the price is reasonable. The display is ok, but some more details are that the ppi is 400 and the screen to body ratio is 80%.\n",
    "Gaming experience is good, but the phone gets heated up after 1 hour of gaming.\n",
    "Netwok connectivity is good. Overall, it is a good phone for the price.\n",
    "\"\"\"\n",
    "\n",
    "# create a review schema\n",
    "\n",
    "class Review(TypedDict):\n",
    "    summary: str\n",
    "    sentiment: str\n",
    "\n",
    "structured_model = model.with_structured_output(Review)\n",
    "response = structured_model.invoke(review)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea00eb8",
   "metadata": {},
   "source": [
    "`with_structured_output` with a schema results in a system prompt behind the scenes which results in generating the response which follows the provided shema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3866d0a",
   "metadata": {},
   "source": [
    "### Using Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "713c563f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentiment': 'positive',\n",
      " 'summary': 'The phone offers a solid camera, long battery life, and a '\n",
      "            'reasonable price. The display is decent with a 400\\u202fppi and '\n",
      "            '80% screen‑to‑body ratio. Gaming is enjoyable but the device '\n",
      "            'tends to heat after an hour. Network connectivity is reliable, '\n",
      "            'making it a good overall value.'}\n"
     ]
    }
   ],
   "source": [
    "class Review(TypedDict):\n",
    "    summary: Annotated[str, \"A summary of the review\"]\n",
    "    sentiment: Annotated[str, \"The sentiment of the review - posutive, negative or neutral\"]\n",
    "\n",
    "structured_model = model.with_structured_output(Review)\n",
    "response = structured_model.invoke(review)\n",
    "pprint(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "1fdb1a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a detailed review for iPhone 17 Air\n",
    "iphone_17_air_review = \"\"\"\n",
    "The iPhone 17 Air represents Apple's boldest design departure in years, delivering an incredibly thin profile that feels almost impossibly light in hand. At just 5.5mm thick, this device pushes the boundaries of engineering while maintaining the premium build quality we expect from Apple. The aerospace-grade aluminum frame feels solid despite its minimal thickness, and the new Ceramic Shield front provides excellent protection without adding bulk. The device comes in four stunning colors: Midnight Black, Starlight Silver, Deep Purple, and a new Ocean Blue that shifts subtly in different lighting conditions.\n",
    "\n",
    "Performance-wise, the iPhone 17 Air doesn't compromise despite its slim form factor. The A18 Bionic chip with its 3nm process delivers exceptional speed and efficiency, handling everything from intensive gaming to professional video editing with ease. The 8GB of unified memory ensures smooth multitasking, and the improved Neural Engine makes AI-powered features incredibly responsive. Battery life is surprisingly robust for such a thin device, easily lasting a full day of heavy usage thanks to the more efficient chip and optimized iOS 18 integration. The new MagSafe wireless charging is faster than ever, reaching 25W speeds that rival many wired chargers.\n",
    "\n",
    "The camera system is where the iPhone 17 Air truly shines, featuring a revolutionary new periscope telephoto lens that somehow fits within the ultra-thin chassis. The main 48MP sensor captures stunning photos with incredible detail and dynamic range, while the new computational photography features produce professional-quality results in challenging lighting conditions. Night mode has been significantly improved, and the new Action mode for video recording delivers gimbal-like stabilization. The front-facing camera now supports 4K ProRes recording, making it perfect for content creators who demand the highest quality.\n",
    "\n",
    "However, the pursuit of thinness does come with some trade-offs. The device can get noticeably warm during intensive tasks, and the reduced internal space means no room for a traditional headphone jack or even the Lightning port - it's USB-C only with wireless charging as the primary power source. The speakers, while clear, lack the depth and bass response of thicker iPhone models. Additionally, the ultra-thin design makes the device feel somewhat fragile, and Apple's recommended case adds back much of the thickness that the Air design eliminates. Despite these minor compromises, the iPhone 17 Air succeeds in creating a truly premium, futuristic smartphone experience that feels like a glimpse into the next decade of mobile technology.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "418c20d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cons': ['Device can get noticeably warm during intensive tasks',\n",
      "          'No headphone jack or Lightning port – USB-C only',\n",
      "          'Speakers lack depth and bass response',\n",
      "          'Ultra-thin design feels somewhat fragile',\n",
      "          \"Apple's recommended case adds back much of the thickness that the \"\n",
      "          'Air design eliminates'],\n",
      " 'key_themes': ['Design and Build',\n",
      "                'Performance and Efficiency',\n",
      "                'Camera System',\n",
      "                'Battery Life and Charging',\n",
      "                'Trade-offs and Limitations'],\n",
      " 'pros': ['Incredibly thin profile at 5.5mm',\n",
      "          'Aerospace-grade aluminum frame',\n",
      "          'Ceramic Shield front protection',\n",
      "          'Stunning color options',\n",
      "          'A18 Bionic chip with 3nm process',\n",
      "          '8GB unified memory',\n",
      "          'Improved Neural Engine',\n",
      "          'Robust battery life',\n",
      "          '25W MagSafe wireless charging',\n",
      "          'Revolutionary periscope telephoto lens',\n",
      "          '48MP main sensor',\n",
      "          'Advanced computational photography',\n",
      "          'Improved night mode',\n",
      "          'Action mode video stabilization',\n",
      "          '4K ProRes front camera'],\n",
      " 'sentiment': 'pos',\n",
      " 'summary': 'The iPhone\\u202f17\\u202fAir is Apple’s boldest design leap, a '\n",
      "            '5.5\\u202fmm ultra‑thin phone that feels surprisingly light yet '\n",
      "            'sturdy thanks to aerospace‑grade aluminum and Ceramic Shield. '\n",
      "            'Powered by the A18\\u202fBionic 3\\u202fnm chip and 8\\u202fGB RAM, '\n",
      "            'it delivers gaming‑grade speed, efficient battery life, and '\n",
      "            '25\\u202fW MagSafe charging. Its camera system shines with a '\n",
      "            'periscope telephoto, 48\\u202fMP sensor, and 4K ProRes front '\n",
      "            'camera, while night and action modes excel. Trade‑offs include '\n",
      "            'heat under load, USB‑C only, weaker speakers, and a fragile feel '\n",
      "            'that a case can mitigate. Overall, a premium, futuristic '\n",
      "            'experience.'}\n"
     ]
    }
   ],
   "source": [
    "class Review(TypedDict):\n",
    "    key_themes: Annotated[list[str], \"The key themes of the review as a list of strings\"]\n",
    "    summary: Annotated[str, \"A brief summary of the review - max 100 words\"]\n",
    "    sentiment: Annotated[Literal[\"pos\", \"neg\", \"neu\"], \"The sentiment of the review\"]\n",
    "    pros: Annotated[Optional[list[str]], \"The pros of the review as a list of strings\"]\n",
    "    cons: Annotated[Optional[list[str]], \"The cons of the review as a list of strings\"]\n",
    "\n",
    "structured_model = model.with_structured_output(Review)\n",
    "response = structured_model.invoke(iphone_17_air_review)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7e7317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cons': [],\n",
      " 'key_themes': ['Design & Build',\n",
      "                'Performance & Efficiency',\n",
      "                'Battery & Charging',\n",
      "                'Camera & Photography',\n",
      "                'User Experience'],\n",
      " 'pros': ['Ultra-thin 5.5mm profile with premium aerospace-grade aluminum '\n",
      "          'frame',\n",
      "          'Exceptional performance from A18 Bionic 3nm chip and 8GB RAM',\n",
      "          'Robust battery life and fast 25W MagSafe charging',\n",
      "          'Revolutionary periscope telephoto lens and 48MP main sensor',\n",
      "          'Advanced computational photography and improved night mode',\n",
      "          'Front camera supports 4K ProRes for creators'],\n",
      " 'sentiment': 'pos',\n",
      " 'summary': 'The iPhone\\u202f17\\u202fAir redefines slimness with a 5.5\\u202fmm '\n",
      "            'chassis that feels surprisingly solid, thanks to aerospace‑grade '\n",
      "            'aluminum and Ceramic Shield. Powered by the A18 Bionic 3\\u202fnm '\n",
      "            'chip and 8\\u202fGB RAM, it delivers gaming‑grade speed, efficient '\n",
      "            'multitasking, and a full day of battery life, complemented by '\n",
      "            '25\\u202fW MagSafe charging. Its standout camera system—48\\u202fMP '\n",
      "            'main sensor, periscope telephoto, and 4K ProRes front '\n",
      "            'camera—offers professional‑level photography and video, while '\n",
      "            'night mode and Action mode shine. Overall, a sleek, '\n",
      "            'high‑performance device that excels in every key area.'}\n"
     ]
    }
   ],
   "source": [
    "# create a detailed review for iPhone 17 Air -- without cons\n",
    "iphone_17_air_review_without_cons = \"\"\"\n",
    "The iPhone 17 Air represents Apple's boldest design departure in years, delivering an incredibly thin profile that feels almost impossibly light in hand. At just 5.5mm thick, this device pushes the boundaries of engineering while maintaining the premium build quality we expect from Apple. The aerospace-grade aluminum frame feels solid despite its minimal thickness, and the new Ceramic Shield front provides excellent protection without adding bulk. The device comes in four stunning colors: Midnight Black, Starlight Silver, Deep Purple, and a new Ocean Blue that shifts subtly in different lighting conditions.\n",
    "\n",
    "Performance-wise, the iPhone 17 Air doesn't compromise despite its slim form factor. The A18 Bionic chip with its 3nm process delivers exceptional speed and efficiency, handling everything from intensive gaming to professional video editing with ease. The 8GB of unified memory ensures smooth multitasking, and the improved Neural Engine makes AI-powered features incredibly responsive. Battery life is surprisingly robust for such a thin device, easily lasting a full day of heavy usage thanks to the more efficient chip and optimized iOS 18 integration. The new MagSafe wireless charging is faster than ever, reaching 25W speeds that rival many wired chargers.\n",
    "\n",
    "The camera system is where the iPhone 17 Air truly shines, featuring a revolutionary new periscope telephoto lens that somehow fits within the ultra-thin chassis. The main 48MP sensor captures stunning photos with incredible detail and dynamic range, while the new computational photography features produce professional-quality results in challenging lighting conditions. Night mode has been significantly improved, and the new Action mode for video recording delivers gimbal-like stabilization. The front-facing camera now supports 4K ProRes recording, making it perfect for content creators who demand the highest quality.\n",
    "\"\"\"\n",
    "\n",
    "structured_model = model.with_structured_output(Review)\n",
    "response = structured_model.invoke(iphone_17_air_review_without_cons)\n",
    "pprint(response)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69e5fca8",
   "metadata": {},
   "source": [
    "This works really well -- but there is no data validation - this can be done by Pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e99f65",
   "metadata": {},
   "source": [
    "### Using Pydantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5946bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "549cc825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='mini'\n"
     ]
    }
   ],
   "source": [
    "class Student(BaseModel):\n",
    "    name: str\n",
    "\n",
    "new_student = {'name': 'mini'}\n",
    "student = Student(**new_student)\n",
    "print(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "faeffa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='mini' age=None\n"
     ]
    }
   ],
   "source": [
    "class Student(BaseModel):\n",
    "    name: str = \"mini\" # default value\n",
    "    age: Optional[int] = None # optional field\n",
    "\n",
    "student = Student()\n",
    "print(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebe96bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='mini' age=29\n"
     ]
    }
   ],
   "source": [
    "# pydantic does type coercion, whenever possible\n",
    "class Student(BaseModel):\n",
    "    name: str = \"mini\"\n",
    "    age: Optional[int] = None\n",
    "\n",
    "student = Student(name=\"mini\", age=\"29\")\n",
    "print(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "41bc3fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='mini' email='mini@example.com'\n"
     ]
    }
   ],
   "source": [
    "# email validation using pydantic\n",
    "from pydantic import EmailStr\n",
    "class User(BaseModel):\n",
    "    name: str\n",
    "    email: EmailStr\n",
    "\n",
    "user = User(name=\"mini\", email=\"mini@example.com\")\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "784a6771",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for User\nemail\n  value is not a valid email address: There must be something after the @-sign. [type=value_error, input_value='mini@', input_type=str]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[98]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m user = \u001b[43mUser\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memail\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmini@\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(user)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/shaunak-dev/LLM-Engineering/.venv/lib/python3.12/site-packages/pydantic/main.py:253\u001b[39m, in \u001b[36mBaseModel.__init__\u001b[39m\u001b[34m(self, **data)\u001b[39m\n\u001b[32m    251\u001b[39m \u001b[38;5;66;03m# `__tracebackhide__` tells pytest and some other tools to omit this function from tracebacks\u001b[39;00m\n\u001b[32m    252\u001b[39m __tracebackhide__ = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m validated_self = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mself_instance\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m validated_self:\n\u001b[32m    255\u001b[39m     warnings.warn(\n\u001b[32m    256\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mA custom validator is returning a value other than `self`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m\n\u001b[32m    257\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mReturning anything other than `self` from a top level model validator isn\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt supported when validating via `__init__`.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mSee the `model_validator` docs (https://docs.pydantic.dev/latest/concepts/validators/#model-validators) for more details.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    259\u001b[39m         stacklevel=\u001b[32m2\u001b[39m,\n\u001b[32m    260\u001b[39m     )\n",
      "\u001b[31mValidationError\u001b[39m: 1 validation error for User\nemail\n  value is not a valid email address: There must be something after the @-sign. [type=value_error, input_value='mini@', input_type=str]"
     ]
    }
   ],
   "source": [
    "user = User(name=\"mini\", email=\"mini@\")\n",
    "print(user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac08465",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='mini' age=20 email='mini@example.com' cgpa=9.5\n"
     ]
    }
   ],
   "source": [
    "# using Field in Pydantic\n",
    "from pydantic import Field\n",
    "\n",
    "\n",
    "class Student(BaseModel):\n",
    "    name: str = \"mini\"\n",
    "    age: Optional[int] = None\n",
    "    email: EmailStr \n",
    "    cgpa: float = Field(ge=0, le=10, default=8.0, description=\"The CGPA of the student\") # description is like the annotation in TypedDict - helps the llm understand the field\n",
    "\n",
    "student = Student(name=\"mini\", age=20, email=\"mini@example.com\", cgpa=9.5)\n",
    "print(student)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8675e3a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name='mini' age=20 email='mini@example.com' cgpa=9.5\n"
     ]
    }
   ],
   "source": [
    "student = Student(name=\"mini\", age=20, email=\"mini@example.com\", cgpa=9.5)\n",
    "print(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05afd185",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'mini', 'age': 20, 'email': 'mini@example.com', 'cgpa': 9.5}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(student)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6c1262b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Review(TypedDict):\n",
    "    key_themes: Annotated[list[str], \"The key themes of the review as a list of strings\"]\n",
    "    summary: Annotated[str, \"A brief summary of the review - max 100 words\"]\n",
    "    sentiment: Annotated[Literal[\"pos\", \"neg\", \"neu\"], \"The sentiment of the review\"]\n",
    "    pros: Annotated[Optional[list[str]], \"The pros of the review as a list of strings\"]\n",
    "    cons: Annotated[Optional[list[str]], \"The cons of the review as a list of strings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3a32554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cons': [],\n",
      " 'key_themes': ['design',\n",
      "                'performance',\n",
      "                'battery',\n",
      "                'camera',\n",
      "                'MagSafe',\n",
      "                'color options'],\n",
      " 'pros': ['ultra-thin 5.5mm profile',\n",
      "          'aerospace-grade aluminum frame',\n",
      "          'Ceramic Shield front',\n",
      "          'four vibrant colors',\n",
      "          'A18 Bionic 3nm chip',\n",
      "          '8GB unified memory',\n",
      "          'Neural Engine AI',\n",
      "          'robust battery life',\n",
      "          '25W MagSafe charging',\n",
      "          'periscope telephoto lens',\n",
      "          '48MP main sensor',\n",
      "          'advanced computational photography',\n",
      "          'improved night mode',\n",
      "          'Action mode stabilization',\n",
      "          '4K ProRes front camera'],\n",
      " 'sentiment': 'pos',\n",
      " 'summary': 'The iPhone\\u202f17\\u202fAir redefines slimness with a 5.5\\u202fmm '\n",
      "            'chassis that feels almost weightless yet feels solid thanks to '\n",
      "            'aerospace‑grade aluminum and Ceramic Shield. Powered by the A18 '\n",
      "            'Bionic 3\\u202fnm chip and 8\\u202fGB memory, it delivers '\n",
      "            'gaming‑grade speed, AI responsiveness, and a full day of battery '\n",
      "            'life, topped by 25\\u202fW MagSafe charging. The camera lineup '\n",
      "            'shines with a periscope telephoto, 48\\u202fMP main sensor, and 4K '\n",
      "            'ProRes front camera, all wrapped in four striking colors. '\n",
      "            'Overall, a sleek, high‑performance device that sets new standards '\n",
      "            'for thinness and photography.'}\n"
     ]
    }
   ],
   "source": [
    "# create a detailed review for iPhone 17 Air -- without cons\n",
    "iphone_17_air_review_without_cons = \"\"\"\n",
    "The iPhone 17 Air represents Apple's boldest design departure in years, delivering an incredibly thin profile that feels almost impossibly light in hand. At just 5.5mm thick, this device pushes the boundaries of engineering while maintaining the premium build quality we expect from Apple. The aerospace-grade aluminum frame feels solid despite its minimal thickness, and the new Ceramic Shield front provides excellent protection without adding bulk. The device comes in four stunning colors: Midnight Black, Starlight Silver, Deep Purple, and a new Ocean Blue that shifts subtly in different lighting conditions.\n",
    "\n",
    "Performance-wise, the iPhone 17 Air doesn't compromise despite its slim form factor. The A18 Bionic chip with its 3nm process delivers exceptional speed and efficiency, handling everything from intensive gaming to professional video editing with ease. The 8GB of unified memory ensures smooth multitasking, and the improved Neural Engine makes AI-powered features incredibly responsive. Battery life is surprisingly robust for such a thin device, easily lasting a full day of heavy usage thanks to the more efficient chip and optimized iOS 18 integration. The new MagSafe wireless charging is faster than ever, reaching 25W speeds that rival many wired chargers.\n",
    "\n",
    "The camera system is where the iPhone 17 Air truly shines, featuring a revolutionary new periscope telephoto lens that somehow fits within the ultra-thin chassis. The main 48MP sensor captures stunning photos with incredible detail and dynamic range, while the new computational photography features produce professional-quality results in challenging lighting conditions. Night mode has been significantly improved, and the new Action mode for video recording delivers gimbal-like stabilization. The front-facing camera now supports 4K ProRes recording, making it perfect for content creators who demand the highest quality.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class Review(BaseModel):\n",
    "    key_themes: List[str] = Field(description=\"The key themes of the review as a list of strings\")\n",
    "    summary: str = Field(description=\"A brief summary of the review - max 100 words\")\n",
    "    sentiment: Literal[\"pos\", \"neg\", \"neu\"] = Field(description=\"The sentiment of the review - posutive, negative or neutral\")\n",
    "    pros: Optional[List[str]] = Field(description=\"The pros of the review as a list of strings\", default=None)\n",
    "    cons: Optional[List[str]] = Field(description=\"The cons of the review as a list of strings\", default=None)\n",
    "\n",
    "structured_model = model.with_structured_output(Review)\n",
    "response = structured_model.invoke(iphone_17_air_review_without_cons)\n",
    "pprint(dict(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "585c4197",
   "metadata": {},
   "source": [
    "### JSON Schema\n",
    "\n",
    "This is useful when u cannot define the structure using python - say u are restricted to a diff langauge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f4ba4041",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Student',\n",
       " 'description': 'A student is a person who is studying at a school or university',\n",
       " 'type': 'object',\n",
       " 'properties': {'name': {'type': 'string',\n",
       "   'description': 'The name of the student'},\n",
       "  'age': {'type': 'integer', 'description': 'The age of the student'}},\n",
       " 'required': ['name']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    "    \"title\": \"Student\",\n",
    "    \"description\": \"A student is a person who is studying at a school or university\",\n",
    "    \"type\": \"object\",\n",
    "    \"properties\": {\n",
    "        \"name\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"The name of the student\"\n",
    "        },\n",
    "        \"age\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"description\": \"The age of the student\"\n",
    "        }\n",
    "    },\n",
    "    \"required\": [\"name\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "543ad7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# review schema\n",
    "# schema\n",
    "json_schema = {\n",
    "  \"title\": \"Review\",\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"key_themes\": {\n",
    "      \"type\": \"array\",\n",
    "      \"items\": {\n",
    "        \"type\": \"string\"\n",
    "      },\n",
    "      \"description\": \"Write down all the key themes discussed in the review in a list\"\n",
    "    },\n",
    "    \"summary\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"A brief summary of the review\"\n",
    "    },\n",
    "    \"sentiment\": {\n",
    "      \"type\": \"string\",\n",
    "      \"enum\": [\"pos\", \"neg\"],\n",
    "      \"description\": \"Return sentiment of the review either negative, positive or neutral\"\n",
    "    },\n",
    "    \"pros\": {\n",
    "      \"type\": [\"array\", \"null\"],\n",
    "      \"items\": {\n",
    "        \"type\": \"string\"\n",
    "      },\n",
    "      \"description\": \"Write down all the pros inside a list\"\n",
    "    },\n",
    "    \"cons\": {\n",
    "      \"type\": [\"array\", \"null\"],\n",
    "      \"items\": {\n",
    "        \"type\": \"string\"\n",
    "      },\n",
    "      \"description\": \"Write down all the cons inside a list\"\n",
    "    },\n",
    "    \"name\": {\n",
    "      \"type\": [\"string\", \"null\"],\n",
    "      \"description\": \"Write the name of the reviewer\"\n",
    "    }\n",
    "  },\n",
    "  \"required\": [\"key_themes\", \"summary\", \"sentiment\"]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9a0dd59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cons': None,\n",
      " 'key_themes': ['Design & Build',\n",
      "                'Performance & Efficiency',\n",
      "                'Battery Life',\n",
      "                'MagSafe Charging',\n",
      "                'Camera System',\n",
      "                'Color Options'],\n",
      " 'name': None,\n",
      " 'pros': ['Ultra‑thin 5.5\\u202fmm profile',\n",
      "          'Lightweight feel',\n",
      "          'Aerospace‑grade aluminum frame',\n",
      "          'Ceramic Shield front',\n",
      "          'Four vibrant color options',\n",
      "          'A18 Bionic 3\\u202fnm chip',\n",
      "          '8\\u202fGB unified memory',\n",
      "          'Neural Engine AI features',\n",
      "          'Full‑day battery life',\n",
      "          '25\\u202fW MagSafe wireless charging',\n",
      "          'Periscope telephoto lens',\n",
      "          '48\\u202fMP main sensor',\n",
      "          'Advanced computational photography',\n",
      "          'Improved Night mode',\n",
      "          'Action mode video stabilization',\n",
      "          '4K ProRes front camera'],\n",
      " 'sentiment': 'pos',\n",
      " 'summary': 'The iPhone\\u202f17\\u202fAir delivers a bold, ultra‑thin design '\n",
      "            'with premium build quality, powerful A18 Bionic performance, '\n",
      "            'robust battery life, fast MagSafe charging, and a standout camera '\n",
      "            'system featuring a periscope telephoto lens and 48\\u202fMP '\n",
      "            'sensor, making it a top choice for both everyday users and '\n",
      "            'content creators.'}\n"
     ]
    }
   ],
   "source": [
    "structured_model = model.with_structured_output(json_schema)\n",
    "\n",
    "response = structured_model.invoke(iphone_17_air_review_without_cons)\n",
    "pprint(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b36743",
   "metadata": {},
   "source": [
    "## Output Parsers\n",
    "\n",
    "If your llm cannot generate structured ops out of the box, we can use Op Parsers -- these are classes in LangChain that help convert raw llm responses into structured ops\n",
    "\n",
    "These can be used both with models which can and cannot provide structured ops"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3483a034",
   "metadata": {},
   "source": [
    "### StrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8d4c9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser, JsonOutputParser\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f62e924b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1st prompt -> detailed report\n",
    "template1 = PromptTemplate(\n",
    "    template='Write a detailed report on {topic}',\n",
    "    input_variables=['topic']\n",
    ")\n",
    "\n",
    "# 2nd prompt -> summary\n",
    "template2 = PromptTemplate(\n",
    "    template='Write a 2 line summary on the following text. /n {text}',\n",
    "    input_variables=['text']\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "47ca412a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This comprehensive report traces AI’s evolution from early symbolic systems to today’s foundation models, detailing core technologies, real‑world applications, and the economic, ethical, and governance challenges they pose. It underscores AI’s transformative impact across industries while calling for responsible design, transparency, and global cooperation to harness its benefits and mitigate risks.'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = template1 | model | parser | template2 | model | parser\n",
    "\n",
    "chain.invoke({\"topic\": \"AI\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e231725d",
   "metadata": {},
   "source": [
    "### JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4483fe48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Return a JSON object.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JsonOutputParser().get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9fbf5990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'facts': ['Black holes are regions of spacetime where gravity is so strong '\n",
      "           'that nothing, not even light, can escape once it crosses the event '\n",
      "           'horizon.',\n",
      "           'The size of a black hole is defined by its Schwarzschild radius, '\n",
      "           'which is proportional to its mass (approximately 3 kilometers per '\n",
      "           'solar mass).',\n",
      "           'Supermassive black holes, with masses millions to billions of '\n",
      "           'times that of the Sun, reside at the centers of most galaxies, '\n",
      "           'including our Milky Way.',\n",
      "           'Black holes can grow by accreting matter from their surroundings '\n",
      "           'or by merging with other black holes, a process that emits '\n",
      "           'powerful gravitational waves detectable by observatories like LIGO '\n",
      "           'and Virgo.',\n",
      "           'Despite their name, black holes are not perfect vacuum; they can '\n",
      "           'emit Hawking radiation—a theoretical quantum effect that causes '\n",
      "           'them to lose mass and eventually evaporate over astronomically '\n",
      "           'long timescales.']}\n"
     ]
    }
   ],
   "source": [
    "parser = JsonOutputParser()\n",
    "\n",
    "template = PromptTemplate(\n",
    "    template='Give me 5 facts about {topic} \\n {format_instruction}',\n",
    "    input_variables=['topic'],\n",
    "    partial_variables={'format_instruction': parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = template | model | parser\n",
    "\n",
    "result = chain.invoke({'topic':'black hole'})\n",
    "\n",
    "pprint(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e6337d",
   "metadata": {},
   "source": [
    "Here its returning in JSON but we __cannot control the schema__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbf99184",
   "metadata": {},
   "source": [
    "### StructuredOutputParser\n",
    "\n",
    "- we can enforce a schema here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fce57c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import StructuredOutputParser, ResponseSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5528b111",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"fact_1\": string  // The first fact about the topic\\n\\t\"fact_2\": string  // The second fact about the topic\\n\\t\"fact_3\": string  // The third fact about the topic\\n\\t\"fact_4\": string  // The fourth fact about the topic\\n\\t\"fact_5\": string  // The fifth fact about the topic\\n}\\n```'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = [ResponseSchema(name=\"fact_1\", description=\"The first fact about the topic\"),\n",
    "ResponseSchema(name=\"fact_2\", description=\"The second fact about the topic\"),\n",
    "ResponseSchema(name=\"fact_3\", description=\"The third fact about the topic\"),\n",
    "ResponseSchema(name=\"fact_4\", description=\"The fourth fact about the topic\"),\n",
    "ResponseSchema(name=\"fact_5\", description=\"The fifth fact about the topic\")\n",
    "]\n",
    "\n",
    "parser = StructuredOutputParser.from_response_schemas(schema)\n",
    "\n",
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db863ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'fact_1': 'A black hole is a region of spacetime where gravity is so strong that nothing, not even light, can escape from it.',\n",
       " 'fact_2': 'The boundary around a black hole beyond which no escape is possible is called the event horizon.',\n",
       " 'fact_3': 'Most black holes form from the remnants of large stars that collapse in on themselves at the end of their life cycle, known as stellar black holes.',\n",
       " 'fact_4': 'Supermassive black holes, millions to billions of times the mass of our Sun, are found at the center of most large galaxies, including our own Milky Way (Sagittarius A*).',\n",
       " 'fact_5': \"Despite their immense gravity, black holes do not 'suck' things in from vast distances; objects must get very close to be pulled in, and if our Sun were replaced by a black hole of the same mass, Earth would continue to orbit it normally.\"}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "template = PromptTemplate(\n",
    "    template='Give me 5 facts about {topic} \\n {format_instruction}',\n",
    "    input_variables=['topic'],\n",
    "    partial_variables={'format_instruction': parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "chain = template | gemini_flash_model | parser # note: this fails with the openai oss model\n",
    "\n",
    "chain.invoke({'topic':'black hole'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707551d7",
   "metadata": {},
   "source": [
    "Disadv\n",
    "\n",
    "- CANNOT do data validation \n",
    "- even if llm sends wrong format, (eg: str instead of int) we cannot validate that"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c58aa50",
   "metadata": {},
   "source": [
    "### PydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "76ab6902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# define schema\n",
    "class Person(BaseModel):\n",
    "    name: str = Field(description=\"The name of the person\")\n",
    "    age: int = Field(description=\"The age of the person\", gt=18, lt=150),\n",
    "    city: str = Field(description=\"The city of the person\")\n",
    "\n",
    "# create parser\n",
    "parser = PydanticOutputParser(pydantic_object=Person)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b934d32a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaunak.sen/Documents/shaunak-dev/LLM-Engineering/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=True, description='The age of the person', metadata=[Gt(gt=18), Lt(lt=150)]),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"name\": {\"description\": \"The name of the person\", \"title\": \"Name\", \"type\": \"string\"}, \"age\": {\"title\": \"Age\", \"type\": \"integer\"}, \"city\": {\"description\": \"The city of the person\", \"title\": \"City\", \"type\": \"string\"}}, \"required\": [\"name\", \"city\"]}\\n```'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685c2f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text='Give me the name, age and city of the person with details: John is 25 years old and lives in New York \\n The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"name\": {\"description\": \"The name of the person\", \"title\": \"Name\", \"type\": \"string\"}, \"age\": {\"title\": \"Age\", \"type\": \"integer\"}, \"city\": {\"description\": \"The city of the person\", \"title\": \"City\", \"type\": \"string\"}}, \"required\": [\"name\", \"city\"]}\\n```'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shaunak.sen/Documents/shaunak-dev/LLM-Engineering/.venv/lib/python3.12/site-packages/pydantic/json_schema.py:2324: PydanticJsonSchemaWarning: Default value (FieldInfo(annotation=NoneType, required=True, description='The age of the person', metadata=[Gt(gt=18), Lt(lt=150)]),) is not JSON serializable; excluding default from JSON schema [non-serializable-default]\n",
      "  warnings.warn(message, PydanticJsonSchemaWarning)\n"
     ]
    }
   ],
   "source": [
    "template = PromptTemplate(\n",
    "    template='Give me the name, age and city of the person with details: {details} \\n {format_instruction}',\n",
    "    input_variables=['details'],\n",
    "    partial_variables={'format_instruction': parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "print (template.invoke({'details':'John is 25 years old and lives in New York'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "156da830",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Person(name='John', age=25, city='New York')"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = template | model | parser\n",
    "\n",
    "chain.invoke({'details':'John is 25 years old and lives in New York'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1826cbb6",
   "metadata": {},
   "source": [
    "## Chains in LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aa77f6",
   "metadata": {},
   "source": [
    "### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "23f49e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Five Fascinating Facts About Black Holes**\n",
      "\n",
      "1. **They’re Not “Vacuum Cleaners”**  \n",
      "   Despite the popular image of a black hole sucking in everything nearby, space around a black hole is essentially empty. Objects only fall in if they cross the event horizon or are on a trajectory that brings them close enough to be captured by the black hole’s gravity.\n",
      "\n",
      "2. **Time Slows Down Near the Event Horizon**  \n",
      "   According to Einstein’s theory of relativity, time runs slower the closer you are to a massive object. Near a black hole’s event horizon, time can dilate to the point where, for an outside observer, an infalling object appears to freeze and fade as it approaches the horizon.\n",
      "\n",
      "3. **They Emit Hawking Radiation**  \n",
      "   In 1974, Stephen Hawking predicted that black holes can emit tiny amounts of thermal radiation due to quantum effects near the event horizon. This “Hawking radiation” means black holes can slowly lose mass and eventually evaporate over astronomically long timescales.\n",
      "\n",
      "4. **The “No‑Hair” Theorem**  \n",
      "   A black hole can be completely described by just three observable properties: mass, electric charge, and angular momentum (spin). All other details about the matter that formed the black hole are lost—hence the phrase “black holes have no hair.”\n",
      "\n",
      "5. **They’re the Ultimate Cosmic Speed Limiters**  \n",
      "   The escape velocity at the event horizon equals the speed of light. Nothing, not even light, can escape once it crosses this boundary. That’s why black holes are invisible—they don’t emit light, but their gravitational influence can be detected through the motion of nearby stars or the bending of light (gravitational lensing).\n"
     ]
    }
   ],
   "source": [
    "prompt = PromptTemplate(\n",
    "    template='Generate 5 interesting facts about {topic}',\n",
    "    input_variables=['topic']\n",
    ")\n",
    "\n",
    "chain = prompt | model | StrOutputParser()\n",
    "\n",
    "print(chain.invoke({'topic':'black hole'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5123d48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     +-------------+       \n",
      "     | PromptInput |       \n",
      "     +-------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "    +----------------+     \n",
      "    | PromptTemplate |     \n",
      "    +----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "      +----------+         \n",
      "      | ChatGroq |         \n",
      "      +----------+         \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "   +-----------------+     \n",
      "   | StrOutputParser |     \n",
      "   +-----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "+-----------------------+  \n",
      "| StrOutputParserOutput |  \n",
      "+-----------------------+  \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "713e6c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Three‑point summary**\n",
      "\n",
      "1. **Cricket’s structure and reach** – A bat‑and‑ball sport governed by the ICC, played worldwide by over 2.5 billion fans. It exists in five main formats (Test, ODI, T20I, The Hundred, domestic first‑class), each with distinct rules, durations, and audiences.\n",
      "\n",
      "2. **Economic and cultural significance** – Cricket generates a multi‑billion‑dollar global market (e.g., IPL >US$1 billion in 2023). It is a national pastime in South Asia, the Caribbean, Australia, England, and New Zealand, shaping identity, media, and even diplomatic relations.\n",
      "\n",
      "3. **Future trajectory** – Technological innovations (DRS, AI analytics, smart gear), new formats (100‑over matches, hybrid games), and sustainability initiatives are reshaping the sport, while expansion into emerging markets (US, China, Africa) and governance reforms aim to balance commercial growth with tradition.\n"
     ]
    }
   ],
   "source": [
    "prompt_detailed_report = PromptTemplate(\n",
    "    template='Write a detailed report on {topic}',\n",
    "    input_variables=['topic']\n",
    ")\n",
    "\n",
    "prompt_key_facts = PromptTemplate(\n",
    "    template='Give me a 3 point summary of the following text: {text}',\n",
    "    input_variables=['text']\n",
    ")\n",
    "\n",
    "chain = prompt_detailed_report | model | StrOutputParser() | prompt_key_facts | model | StrOutputParser()\n",
    "\n",
    "\n",
    "print(chain.invoke({'topic':'cricket'})) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "682b6da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     +-------------+       \n",
      "     | PromptInput |       \n",
      "     +-------------+       \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "    +----------------+     \n",
      "    | PromptTemplate |     \n",
      "    +----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "      +----------+         \n",
      "      | ChatGroq |         \n",
      "      +----------+         \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "   +-----------------+     \n",
      "   | StrOutputParser |     \n",
      "   +-----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "    +----------------+     \n",
      "    | PromptTemplate |     \n",
      "    +----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "      +----------+         \n",
      "      | ChatGroq |         \n",
      "      +----------+         \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "   +-----------------+     \n",
      "   | StrOutputParser |     \n",
      "   +-----------------+     \n",
      "            *              \n",
      "            *              \n",
      "            *              \n",
      "+-----------------------+  \n",
      "| StrOutputParserOutput |  \n",
      "+-----------------------+  \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427d62f4",
   "metadata": {},
   "source": [
    "### Parallel Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "db0433b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_1 = PromptTemplate(\n",
    "    template=\"Generate short and simple notes from the following text: {text}\",\n",
    "    input_variables=['text']\n",
    ")\n",
    "\n",
    "prompt_2 = PromptTemplate(\n",
    "    template=\"Generate 5 short simple QnAs like a quiz from the following text: {text}\",\n",
    "    input_variables=['text']\n",
    ")\n",
    "\n",
    "\n",
    "prompt_3 = PromptTemplate(\n",
    "    template=\"Merge the provided notes and quiz into a single document \\n {notes} \\n {quiz}\",\n",
    "    input_variables=['notes', 'quiz']\n",
    ")\n",
    "\n",
    "parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9a00b0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.runnable import RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "56b27955",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = model.invoke(\"Generate a detailed report on Attention is all you need paper\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "970a80de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Attention Is All You Need  \n",
      "**Vaswani, A., Shazeer, N., Parmar, N., Uszkoreit, J., Jones, L., Gomez, A. N., Kaiser, Ł., & Polosukhin, I. (2017).** *Attention Is All You Need*. In *Advances in Neural Information Processing Systems* (NeurIPS 2017).  \n",
      "\n",
      "---\n",
      "\n",
      "## 1. Executive Summary  \n",
      "\n",
      "The 2017 NeurIPS paper “Attention Is All You Need” introduced the **Transformer** architecture, a novel neural network model that dispenses with recurrence and convolution entirely, relying solely on a **self‑attention** mechanism. The Transformer achieved state‑of‑the‑art results on several machine‑translation benchmarks (WMT 2014 English‑German and English‑French) while dramatically reducing training time and enabling far larger parallelism. Its design has since become the backbone of virtually all modern large‑scale language models (BERT, GPT, T5, etc.).\n",
      "\n",
      "Key innovations:\n",
      "\n",
      "| Innovation | What it solves | Impact |\n",
      "|------------|----------------|--------|\n",
      "| **Scaled Dot‑Product Attention** | Efficient, differentiable weighting of input tokens | Core building block |\n",
      "| **Multi‑Head Attention** | Captures multiple representation sub‑spaces | Richer context |\n",
      "| **Positional Encoding (sinusoidal)** | Injects token order without recurrence | Enables parallel training |\n",
      "| **Layer Normalization & Residual Connections** | Stabilizes training | Faster convergence |\n",
      "| **Feed‑Forward Networks (position‑wise)** | Adds non‑linearity | Enhances expressiveness |\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Background & Motivation  \n",
      "\n",
      "### 2.1 Prior Approaches  \n",
      "- **Recurrent Neural Networks (RNNs)** (LSTM/GRU) – sequential processing, limited parallelism, difficulty learning long‑range dependencies.  \n",
      "- **Convolutional Neural Networks (CNNs)** – improved parallelism but still limited receptive field; required many layers for long‑range context.  \n",
      "- **Hybrid RNN‑CNN** – e.g., ConvS2S, still had sequential bottlenecks.\n",
      "\n",
      "### 2.2 Limitations of Recurrence & Convolution  \n",
      "1. **Sequential Bottleneck** – Each token must wait for the previous one.  \n",
      "2. **Gradient Vanishing / Exploding** – Hard to train deep models.  \n",
      "3. **Limited Parallelism** – Training time scales poorly with sequence length.  \n",
      "4. **Difficulty Capturing Global Context** – Convolutions have limited receptive fields; RNNs rely on hidden state.\n",
      "\n",
      "### 2.3 The Idea: “Attention Is All You Need”  \n",
      "- Replace recurrence and convolution with a **self‑attention** mechanism that directly relates every token to every other token in a single layer.  \n",
      "- Use **parallelizable operations** (matrix multiplications) to enable GPU/TPU scaling.  \n",
      "- Introduce **positional encodings** to provide order information without recurrence.\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Model Architecture  \n",
      "\n",
      "The Transformer is a **sequence‑to‑sequence** model composed of an **encoder** and a **decoder**, each a stack of identical layers. The architecture is fully modular and can be adapted to many tasks beyond translation.\n",
      "\n",
      "### 3.1 Notation  \n",
      "\n",
      "- Input sequence: \\(X = (x_1, x_2, \\dots, x_n)\\).  \n",
      "- Embedding dimension: \\(d_{\\text{model}}\\).  \n",
      "- Number of attention heads: \\(h\\).  \n",
      "- Dimension per head: \\(d_k = d_{\\text{model}} / h\\).  \n",
      "- Feed‑forward hidden size: \\(d_{\\text{ff}}\\).  \n",
      "\n",
      "### 3.2 Encoder Layer  \n",
      "\n",
      "```\n",
      "Input:  X (batch, seq_len, d_model)\n",
      "1. Multi‑Head Self‑Attention (MHSA)\n",
      "   Q = XW_Q, K = XW_K, V = XW_V\n",
      "   Attention_i = softmax((Q_i K_i^T) / sqrt(d_k)) V_i\n",
      "   Concatenate heads → X' = Concat(Attention_1,...,Attention_h) W_O\n",
      "2. Add & Norm: X'' = LayerNorm(X + X')\n",
      "3. Position‑wise Feed‑Forward (FFN)\n",
      "   FFN(x) = max(0, xW_1 + b_1)W_2 + b_2\n",
      "4. Add & Norm: Output = LayerNorm(X'' + FFN(X''))\n",
      "```\n",
      "\n",
      "- **Residual connections** (add) + **Layer Normalization** after each sub‑layer.  \n",
      "- **Dropout** applied after attention and FFN.\n",
      "\n",
      "### 3.3 Decoder Layer  \n",
      "\n",
      "```\n",
      "Input:  Y (target sequence), Encoder output E\n",
      "1. Masked Multi‑Head Self‑Attention (causal)\n",
      "   Same as encoder but with mask to prevent attending to future tokens.\n",
      "2. Add & Norm: Y' = LayerNorm(Y + MaskedAttention)\n",
      "3. Multi‑Head Encoder‑Decoder Attention\n",
      "   Q = Y'W_Q, K = EW_K, V = EW_V\n",
      "   Attention = softmax((Q K^T)/sqrt(d_k)) V\n",
      "4. Add & Norm: Y'' = LayerNorm(Y' + Attention)\n",
      "5. Position‑wise FFN\n",
      "6. Add & Norm: Output = LayerNorm(Y'' + FFN(Y''))\n",
      "```\n",
      "\n",
      "- **Causal mask** ensures autoregressive property during training and inference.  \n",
      "- **Encoder‑Decoder attention** allows the decoder to focus on relevant encoder states.\n",
      "\n",
      "### 3.4 Positional Encoding  \n",
      "\n",
      "Two variants:\n",
      "\n",
      "1. **Sinusoidal** (used in the paper):\n",
      "\n",
      "\\[\n",
      "\\text{PE}_{(pos, 2i)} = \\sin\\!\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right), \\quad\n",
      "\\text{PE}_{(pos, 2i+1)} = \\cos\\!\\left(\\frac{pos}{10000^{2i/d_{\\text{model}}}}\\right)\n",
      "\\]\n",
      "\n",
      "2. **Learned** (later variants).\n",
      "\n",
      "The positional encodings are added to token embeddings before feeding into the encoder/decoder.\n",
      "\n",
      "### 3.5 Hyperparameters (Base Model)  \n",
      "\n",
      "| Component | Value |\n",
      "|-----------|-------|\n",
      "| \\(d_{\\text{model}}\\) | 512 |\n",
      "| \\(h\\) | 8 |\n",
      "| \\(d_k = d_v\\) | 64 |\n",
      "| \\(d_{\\text{ff}}\\) | 2048 |\n",
      "| Layers (encoder/decoder) | 6 |\n",
      "| Dropout | 0.1 |\n",
      "| Optimizer | Adam (β1=0.9, β2=0.98, ε=10⁻⁹) |\n",
      "| Learning rate schedule | Warmup + inverse‑sqrt decay |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Training Procedure  \n",
      "\n",
      "1. **Data** – WMT 2014 English‑German (≈4.5M sentence pairs) and English‑French (≈36M).  \n",
      "2. **Tokenization** – Byte‑Pair Encoding (BPE) with 32k merge operations.  \n",
      "3. **Loss** – Cross‑entropy over target tokens.  \n",
      "4. **Optimizer** – Adam with warmup steps (4000) and learning rate schedule:\n",
      "\n",
      "\\[\n",
      "lrate = d_{\\text{model}}^{-0.5} \\min\\!\\left(step^{-0.5}, step \\cdot warmup^{-1.5}\\right)\n",
      "\\]\n",
      "\n",
      "5. **Batching** – Fixed number of tokens per batch (~4096).  \n",
      "6. **Regularization** – Dropout, label smoothing (ε=0.1).  \n",
      "7. **Inference** – Beam search (beam size 4–8), length penalty.\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Experimental Results  \n",
      "\n",
      "| Task | Model | BLEU (English‑German) | BLEU (English‑French) | Training Time (GPU hours) |\n",
      "|------|-------|-----------------------|-----------------------|---------------------------|\n",
      "| WMT 2014 | Transformer (Base) | **28.4** | **41.0** | ~4 days on 8 GPUs |\n",
      "| WMT 2014 | ConvS2S (baseline) | 27.3 | 39.8 | ~6 days |\n",
      "| WMT 2014 | LSTM (baseline) | 24.6 | 36.5 | ~10 days |\n",
      "\n",
      "- **Speed**: Transformer converges in ~4 days vs. ~10 days for LSTM.  \n",
      "- **Accuracy**: 4–5 BLEU points improvement over the best RNN/CNN baselines.  \n",
      "- **Scalability**: Training time scales linearly with GPU count; no sequential bottleneck.\n",
      "\n",
      "The paper also reports ablation studies:\n",
      "\n",
      "- Removing positional encodings → BLEU drops by ~3 points.  \n",
      "- Using learned positional encodings → similar performance.  \n",
      "- Reducing number of heads → slight drop; more heads improve performance.  \n",
      "- Removing residual connections → training diverges.\n",
      "\n",
      "---\n",
      "\n",
      "## 6. Analysis of Core Components  \n",
      "\n",
      "### 6.1 Scaled Dot‑Product Attention  \n",
      "\n",
      "\\[\n",
      "\\text{Attention}(Q, K, V) = \\text{softmax}\\!\\left(\\frac{QK^T}{\\sqrt{d_k}}\\right)V\n",
      "\\]\n",
      "\n",
      "- **Scaling** by \\(\\sqrt{d_k}\\) prevents large dot‑products from pushing softmax into regions with very small gradients.  \n",
      "- **Computational Complexity**: \\(O(n^2 d_{\\text{model}})\\) per layer, but highly parallelizable.\n",
      "\n",
      "### 6.2 Multi‑Head Attention  \n",
      "\n",
      "- Splits queries, keys, values into \\(h\\) sub‑spaces.  \n",
      "- Each head learns a different representation (e.g., syntactic vs. semantic).  \n",
      "- Concatenation + linear projection restores dimensionality.\n",
      "\n",
      "### 6.3 Positional Encoding  \n",
      "\n",
      "- **Sinusoidal** functions allow the model to extrapolate to longer sequences (due to periodicity).  \n",
      "- **Learned** variants (later work) can adapt better to specific datasets but risk overfitting.\n",
      "\n",
      "### 6.4 Layer Normalization vs. Batch Normalization  \n",
      "\n",
      "- LayerNorm operates over the feature dimension, independent of batch size, making it suitable for sequence models where batch sizes can be small.\n",
      "\n",
      "### 6.5 Residual Connections  \n",
      "\n",
      "- Facilitate gradient flow, enabling deeper stacks (12‑layer encoder/decoder in later variants).  \n",
      "- Empirically reduce training loss and improve generalization.\n",
      "\n",
      "---\n",
      "\n",
      "## 7. Impact & Legacy  \n",
      "\n",
      "| Year | Model | Key Contribution | Relation to Transformer |\n",
      "|------|-------|------------------|------------------------|\n",
      "| 2018 | BERT (Devlin et al.) | Masked LM + Next Sentence Prediction | Uses Transformer encoder; pre‑training paradigm |\n",
      "| 2018 | GPT (Radford et al.) | Autoregressive language modeling | Uses Transformer decoder; large‑scale pre‑training |\n",
      "| 2019 | Transformer‑XL (Dai et al.) | Recurrence across segments | Extends Transformer with memory |\n",
      "| 2019 | T5 (Raffel et al.) | Text‑to‑text framework | Uses encoder‑decoder Transformer |\n",
      "| 2020 | GPT‑3 (Brown et al.) | 175B parameters | Massive scaling of Transformer decoder |\n",
      "| 2021 | Switch‑Transformer (Fedus et al.) | Mixture‑of‑Experts | Sparse attention within Transformer |\n",
      "| 2023 | PaLM (Chowdhery et al.) | 540B parameters | Large‑scale multi‑modal Transformer |\n",
      "\n",
      "The Transformer has become the **de‑facto standard** for NLP, and its principles have been adapted to vision (ViT), audio, and multimodal tasks.\n",
      "\n",
      "---\n",
      "\n",
      "## 8. Strengths & Weaknesses  \n",
      "\n",
      "| Strength | Explanation |\n",
      "|----------|-------------|\n",
      "| **Parallelism** | Entire sequence processed in one forward pass. |\n",
      "| **Long‑Range Dependencies** | Direct connections between any two tokens. |\n",
      "| **Modularity** | Easy to stack layers, add heads, or change sub‑modules. |\n",
      "| **Scalability** | Works well on GPUs/TPUs; training time grows sub‑linearly with model size. |\n",
      "| **Transferability** | Encoder/decoder can be fine‑tuned for diverse tasks. |\n",
      "\n",
      "| Weakness | Explanation |\n",
      "|----------|-------------|\n",
      "| **Quadratic Complexity** | Attention cost \\(O(n^2)\\) limits sequence length (though sparse attention variants mitigate). |\n",
      "| **Memory Footprint** | Large models require significant GPU memory; often need model parallelism. |\n",
      "| **Positional Bias** | Fixed positional encodings may not capture complex positional relationships; learned encodings help but add parameters. |\n",
      "| **Interpretability** | Attention weights are not always faithful explanations of model decisions. |\n",
      "\n",
      "---\n",
      "\n",
      "## 9. Extensions & Variants  \n",
      "\n",
      "| Variant | What Changed | Why |\n",
      "|---------|--------------|-----|\n",
      "| **Transformer‑XL** | Recurrence across segments + relative positional encodings | Handles longer contexts without quadratic cost. |\n",
      "| **Sparse Transformer** | Sparse attention patterns (e.g., local + global) | Reduces complexity to \\(O(n \\log n)\\). |\n",
      "| **Linformer** | Low‑rank projection of keys/values | Linear complexity in sequence length. |\n",
      "| **Performer** | Random feature maps for kernelized attention | Approximate attention in linear time. |\n",
      "| **Longformer** | Sliding window + global attention | Efficient for very long documents. |\n",
      "| **Switch‑Transformer** | Mixture‑of‑Experts (MoE) | Sparse activation of experts to scale parameters without quadratic cost. |\n",
      "\n",
      "---\n",
      "\n",
      "## 10. Future Directions  \n",
      "\n",
      "1. **Efficient Attention** – Continued research into linear‑time attention mechanisms (e.g., Performer, Reformer).  \n",
      "2. **Dynamic Positional Encoding** – Learnable or adaptive encodings that capture hierarchical structure.  \n",
      "3. **Multimodal Transformers** – Unified models for vision, audio, and text (e.g., CLIP, DALL‑E).  \n",
      "4. **Sparse & Structured Attention** – Combining locality with global context for long‑form generation.  \n",
      "5. **Interpretability & Robustness** – Better understanding of attention patterns, adversarial robustness.  \n",
      "6. **Hardware‑aware Design** – Optimizing for emerging accelerators (TPUs, GPUs, neuromorphic chips).  \n",
      "\n",
      "---\n",
      "\n",
      "## 11. Key Takeaways  \n",
      "\n",
      "- The Transformer demonstrates that **self‑attention alone** can replace recurrence and convolution for sequence modeling.  \n",
      "- Its **parallelizable architecture** and **scalable training** made it feasible to train massive language models.  \n",
      "- The paper’s **design principles** (scaled dot‑product, multi‑head, positional encoding, residual + layer norm) remain foundational in modern NLP.  \n",
      "- Subsequent research has built upon and extended the Transformer in numerous directions, cementing its status as a cornerstone of deep learning.\n",
      "\n",
      "---\n",
      "\n",
      "## 12. References  \n",
      "\n",
      "1. Vaswani, A., Shazeer, N., Parmar, N., et al. (2017). *Attention Is All You Need*. NeurIPS 2017.  \n",
      "2. Devlin, J., Chang, M.-W., Lee, K., & Toutanova, K. (2019). *BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding*. NAACL.  \n",
      "3. Radford, A., Narasimhan, K., Salimans, T., & Sutskever, I. (2018). *Improving Language Understanding by Generative Pre‑Training*.  \n",
      "4. Dai, Z., Yang, Z., Yang, Y., et al. (2019). *Transformer‑XL: Attentive Language Models Beyond a Fixed-Length Context*. arXiv:1901.02860.  \n",
      "5. Raffel, C., Shazeer, N., Roberts, A., et al. (2020). *Exploring the Limits of Transfer Learning with a Unified Text‑to‑Text Transformer*. JMLR.  \n",
      "6. Brown, T. B., Mann, B., Ryder, N., et al. (2020). *Language Models are Few‑Shot Learners*. NeurIPS 2020.  \n",
      "7. Fedus, W., Zoph, B., & Le, Q. V. (2021). *Switch Transformers: Scaling to Trillion‑Parameter Models with Simple Sparsity*. arXiv:2101.03961.  \n",
      "8. Chowdhery, N., et al. (2022). *PaLM: Scaling Language Modeling with Pathways*. arXiv:2204.02311.  \n",
      "\n",
      "---  \n",
      "\n",
      "*Prepared by ChatGPT – OpenAI, 2025‑09‑14.*\n"
     ]
    }
   ],
   "source": [
    "print (text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ad96641a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# “Attention Is All You Need” – Short & Simple Notes + Quiz  \n",
      "*(Vaswani et al., 2017 – NeurIPS)*  \n",
      "\n",
      "---\n",
      "\n",
      "## 1. What It Is  \n",
      "The **Transformer** – a neural‑network architecture that relies **only on self‑attention** (no RNNs or CNNs). It became the foundation for BERT, GPT, T5, and many other state‑of‑the‑art language models.\n",
      "\n",
      "---\n",
      "\n",
      "## 2. Why It Matters  \n",
      "\n",
      "| Benefit | Why It Matters |\n",
      "|---------|----------------|\n",
      "| **Faster training** | Fully parallelizable – no sequential bottleneck. |\n",
      "| **Higher accuracy** | Outperformed RNN/CNN baselines on WMT 2014 (BLEU 28.4 EN‑DE, 41.0 EN‑FR). |\n",
      "| **Scalable** | Works on GPUs/TPUs; training time grows linearly with GPU count. |\n",
      "| **Modular** | Easy to stack, adapt, or extend (e.g., BERT, GPT). |\n",
      "\n",
      "---\n",
      "\n",
      "## 3. Core Ideas  \n",
      "\n",
      "| Idea | Purpose | Effect |\n",
      "|------|---------|--------|\n",
      "| **Scaled Dot‑Product Attention** | Efficiently weighs token relationships | Core building block |\n",
      "| **Multi‑Head Attention** | Learns multiple “views” of the data | Richer context |\n",
      "| **Sinusoidal Positional Encoding** | Gives token order without recurrence | Enables parallelism |\n",
      "| **LayerNorm + Residuals** | Stabilizes training | Faster convergence |\n",
      "| **Position‑wise Feed‑Forward** | Adds non‑linearity | More expressive power |\n",
      "\n",
      "---\n",
      "\n",
      "## 4. Architecture Overview  \n",
      "\n",
      "| Component | Structure (per layer) | Key Hyper‑params (Base) |\n",
      "|-----------|-----------------------|------------------------|\n",
      "| **Encoder** | `Self‑Attention → Add+Norm → FFN → Add+Norm` (×6) | `d_model=512`, `h=8` heads (`d_k=64`), `d_ff=2048`, dropout 0.1 |\n",
      "| **Decoder** | `Masked Self‑Attention → Add+Norm → Encoder‑Decoder Attention → Add+Norm → FFN → Add+Norm` (×6) | Same as encoder |\n",
      "| **Optimizer** | Adam (warm‑up + inverse‑sqrt LR schedule) |  |\n",
      "\n",
      "---\n",
      "\n",
      "## 5. Training Highlights  \n",
      "\n",
      "| Item | Detail |\n",
      "|------|--------|\n",
      "| **Data** | WMT 2014 English‑German / French |\n",
      "| **Tokenization** | Byte‑Pair Encoding (32k merges) |\n",
      "| **Loss** | Cross‑entropy + label smoothing |\n",
      "| **Batch** | ~4096 tokens |\n",
      "| **Training time** | ~4 days on 8 GPUs (vs. ~10 days for LSTM) |\n",
      "| **Results** | BLEU 28.4 (EN‑DE), 41.0 (EN‑FR) – 4–5 BLEU points better than RNN/CNN baselines |\n",
      "\n",
      "---\n",
      "\n",
      "## 6. Strengths  \n",
      "\n",
      "* **Parallel** – no sequential bottleneck.  \n",
      "* **Long‑range dependencies** – direct token‑to‑token connections.  \n",
      "* **Modular** – easy to stack, adapt, or extend.  \n",
      "* **Scalable** – works on GPUs/TPUs; training time grows linearly with GPU count.  \n",
      "\n",
      "---\n",
      "\n",
      "## 7. Weaknesses  \n",
      "\n",
      "* **Quadratic cost** in sequence length (`O(n²)` attention).  \n",
      "* **Memory heavy** for very large models.  \n",
      "* **Positional encoding** may not capture complex order patterns.  \n",
      "* **Attention not always interpretable**.  \n",
      "\n",
      "---\n",
      "\n",
      "## 8. Extensions (post‑2017)  \n",
      "\n",
      "| Model | Key Feature |\n",
      "|-------|-------------|\n",
      "| **BERT** | Encoder‑only, masked LM |\n",
      "| **GPT** | Decoder‑only, autoregressive LM |\n",
      "| **Transformer‑XL** | Recurrence across segments |\n",
      "| **Sparse/Linear attention** (Longformer, Performer) | Reduce `O(n²)` cost |\n",
      "| **Mixture‑of‑Experts** (Switch‑Transformer) | Scale parameters sparsely |\n",
      "\n",
      "---\n",
      "\n",
      "## 9. Take‑away  \n",
      "The Transformer proved that *self‑attention alone* can replace recurrence and convolution for sequence modeling, enabling faster, more accurate, and highly scalable language models that dominate modern NLP.\n",
      "\n",
      "---\n",
      "\n",
      "# Quiz – “Attention Is All You Need”\n",
      "\n",
      "| # | Question | Answer |\n",
      "|---|----------|--------|\n",
      "| 1 | What neural‑network architecture did the 2017 NeurIPS paper introduce? | The **Transformer** architecture. |\n",
      "| 2 | Which two key mechanisms replace recurrence and convolution in the Transformer? | **Self‑attention** (scaled dot‑product) and **multi‑head attention**. |\n",
      "| 3 | How does the Transformer give the model a sense of token order? | By adding **positional encodings** (sinusoidal in the original paper). |\n",
      "| 4 | What two components are added after each sub‑layer to stabilize training? | **Residual connections** and **Layer Normalization**. |\n",
      "| 5 | Name one major language model that uses the Transformer as its backbone. | **BERT**, **GPT**, or **T5** (any one of them). |\n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# define the parallel chain\n",
    "\n",
    "parallel_chain = RunnableParallel({\n",
    "    \"notes\": prompt_1 | model | StrOutputParser(),\n",
    "    \"quiz\": prompt_2 | model | StrOutputParser(),\n",
    "})\n",
    "\n",
    "# define the sequential chain for merging\n",
    "\n",
    "merge_chain = prompt_3 | model | parser\n",
    "\n",
    "# combine the parallel and sequential chains\n",
    "\n",
    "chain = parallel_chain | merge_chain\n",
    "\n",
    "print(chain.invoke({\"text\":text}))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6882de00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          +---------------------------+            \n",
      "          | Parallel<notes,quiz>Input |            \n",
      "          +---------------------------+            \n",
      "                ***             ***                \n",
      "              **                   **              \n",
      "            **                       **            \n",
      "+----------------+              +----------------+ \n",
      "| PromptTemplate |              | PromptTemplate | \n",
      "+----------------+              +----------------+ \n",
      "          *                             *          \n",
      "          *                             *          \n",
      "          *                             *          \n",
      "    +----------+                  +----------+     \n",
      "    | ChatGroq |                  | ChatGroq |     \n",
      "    +----------+                  +----------+     \n",
      "          *                             *          \n",
      "          *                             *          \n",
      "          *                             *          \n",
      "+-----------------+            +-----------------+ \n",
      "| StrOutputParser |            | StrOutputParser | \n",
      "+-----------------+            +-----------------+ \n",
      "                ***             ***                \n",
      "                   **         **                   \n",
      "                     **     **                     \n",
      "          +----------------------------+           \n",
      "          | Parallel<notes,quiz>Output |           \n",
      "          +----------------------------+           \n",
      "                         *                         \n",
      "                         *                         \n",
      "                         *                         \n",
      "                +----------------+                 \n",
      "                | PromptTemplate |                 \n",
      "                +----------------+                 \n",
      "                         *                         \n",
      "                         *                         \n",
      "                         *                         \n",
      "                   +----------+                    \n",
      "                   | ChatGroq |                    \n",
      "                   +----------+                    \n",
      "                         *                         \n",
      "                         *                         \n",
      "                         *                         \n",
      "                +-----------------+                \n",
      "                | StrOutputParser |                \n",
      "                +-----------------+                \n",
      "                         *                         \n",
      "                         *                         \n",
      "                         *                         \n",
      "            +-----------------------+              \n",
      "            | StrOutputParserOutput |              \n",
      "            +-----------------------+              \n"
     ]
    }
   ],
   "source": [
    "chain.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b96602",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
