{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e405d6b3",
   "metadata": {},
   "source": [
    "## Testing out the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ac4fd8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import ChatHuggingFace, HuggingFaceEndpoint\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from dotenv import load_dotenv\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22ae9354",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()  # Load environment variables from a .env file if present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25e122c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.3.27'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ca2cb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini_flash_model = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    # other params...\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abaff17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(\n",
    "    model=\"openai/gpt-oss-20b\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    reasoning_format=\"parsed\",\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "638d62ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is **New\\u202fDelhi**.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"what is the capital of india\").content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f6db1cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of India is **New Delhi**.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gemini_flash_model.invoke(\"what is the capital of india\").content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab9039a1",
   "metadata": {},
   "source": [
    "### Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39946a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.03572908416390419,\n",
       " 0.014558478258550167,\n",
       " 0.011592254973948002,\n",
       " -0.08969993889331818,\n",
       " -0.009068180806934834,\n",
       " 0.013664662837982178,\n",
       " 0.011340967379510403,\n",
       " -0.005701108369976282,\n",
       " -0.027033332735300064,\n",
       " 3.775993536692113e-05]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model = GoogleGenerativeAIEmbeddings(model=\"gemini-embedding-001\")\n",
    "embeddings = embedding_model.embed_query(text=\"What's our Q1 revenue?\", output_dimensionality=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "442f4ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c83f8c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs={\"device\": \"cpu\"},\n",
    ")\n",
    "embeddings = embedding_model.embed_query(text=\"What's our Q1 revenue?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "469390e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "384"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ac8699",
   "metadata": {},
   "source": [
    "## Langchain Prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f770da5",
   "metadata": {},
   "source": [
    "### Basic Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "08a51825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import PromptTemplate, load_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c604238",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = PromptTemplate(\n",
    "    template=\"\"\"\n",
    "    You are a helpful assistant that can generate a short report on the topic: {paper_input}\n",
    "    The report should be in the style of {style_input} and the length should be {length_input}\n",
    "    \"\"\",\n",
    "    input_variables=[\"paper_input\", \"style_input\", \"length_input\"]\n",
    ")\n",
    "\n",
    "template.save(\"./prompt_templates/template.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3dfce506",
   "metadata": {},
   "outputs": [],
   "source": [
    "template = load_prompt(\"./prompt_templates/template.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "34432a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = template.format(\n",
    "        paper_input=\"Attention is all you need\", style_input=\"Beginner-Friendly\", length_input=\"Short (1-2 paragraphs)\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1cea0e2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    You are a helpful assistant that can generate a short report on the topic: Attention is all you need\n",
      "    The report should be in the style of Beginner-Friendly and the length should be Short (1-2 paragraphs)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "print (prompt)\n",
    "\n",
    "### Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7c294e",
   "metadata": {},
   "source": [
    "### Messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d88b3774",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage, AIMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1ac7f7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The capital of France is **Paris**.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant that can answer questions and help with tasks.\"),\n",
    "    HumanMessage(content=\"What is the capital of France?\"),\n",
    "]\n",
    "\n",
    "result = model.invoke(messages)\n",
    "\n",
    "result.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d2d852",
   "metadata": {},
   "source": [
    "### Dynammic list of messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1dcdaaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_template = ChatPromptTemplate(messages=[\n",
    "    SystemMessage(content=\"You are a helpful assistant who is an expert in the domain: {domain}\"),\n",
    "    HumanMessage(content=\"Explain the topic in simple terms: {topic}\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "37fc3c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful assistant who is an expert in the domain: {domain}', additional_kwargs={}, response_metadata={}), HumanMessage(content='Explain the topic in simple terms: {topic}', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "prompt = chat_template.invoke({\"domain\": \"AI\", \"topic\": \"Self Attention\"})\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b60a1e",
   "metadata": {},
   "source": [
    "### The above does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "03bbd30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a helpful assistant who is an expert in the domain: AI', additional_kwargs={}, response_metadata={}), HumanMessage(content='Explain the topic in simple terms in 3-5 sentences: Self Attention', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "chat_template = ChatPromptTemplate(messages=[\n",
    "    (\"system\", \"You are a helpful assistant who is an expert in the domain: {domain}\"),\n",
    "    (\"human\", \"Explain the topic in simple terms in 3-5 sentences: {topic}\"),\n",
    "])\n",
    "prompt = chat_template.invoke({\"domain\": \"AI\", \"topic\": \"Self Attention\"})\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "69b273c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self‑attention is a way for a model to look at all the words in a sentence at once and decide how much each word should influence every other word.  \n",
      "For each word, the model creates three vectors—query, key, and value—then compares the query of one word with the keys of all words to get a “similarity score.”  \n",
      "These scores are turned into weights (via a softmax) that say how much attention each word should give to the others, and the weighted sum of the value vectors gives the new representation for that word.  \n",
      "Because every word can attend to every other word, the model captures long‑range relationships and context without needing to process the sentence sequentially.  \n",
      "This mechanism is the core of transformer models, enabling them to understand and generate language efficiently.\n"
     ]
    }
   ],
   "source": [
    "result = model.invoke(prompt)\n",
    "print(result.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531a16a3",
   "metadata": {},
   "source": [
    "### Message Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "fe629272",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_messages = [\n",
    "    HumanMessage(content=\"I want to request a refund for my order #12345.\"),\n",
    "    AIMessage(content=\"Your refund request for order #12345 has been initiated. It will be processed in 3-5 business days.\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "59e7906d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to request a refund for my order #12345.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_messages[0].content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "55493bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatPromptValue(messages=[SystemMessage(content='You are a helpful assistant that can answer questions and help with tasks.', additional_kwargs={}, response_metadata={}), HumanMessage(content='I want to request a refund for my order #12345.', additional_kwargs={}, response_metadata={}), AIMessage(content='Your refund request for order #12345 has been initiated. It will be processed in 3-5 business days.', additional_kwargs={}, response_metadata={}), HumanMessage(content='how many day again?', additional_kwargs={}, response_metadata={})])\n"
     ]
    }
   ],
   "source": [
    "chat_template = ChatPromptTemplate(messages=[\n",
    "    (\"system\", \"You are a helpful assistant that can answer questions and help with tasks.\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{query}\"),\n",
    "])\n",
    "\n",
    "prompt = chat_template.invoke({\"query\": \"how many day again?\", \"chat_history\": history_messages})\n",
    "\n",
    "pprint(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "186112e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It will take **3–5 business days** to complete the refund.  \n",
      "That means the processing time is counted only on weekdays (Monday‑Friday), excluding public holidays. If you have any more questions, just let me know!\n"
     ]
    }
   ],
   "source": [
    "response = model.invoke(prompt)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf059d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
